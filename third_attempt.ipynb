{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "Collecting regex (from nltk)\n",
      "  Using cached https://files.pythonhosted.org/packages/84/cb/e7792d2c52f61a686ce0fabe79b3674c41238d07cd35c79b4062e9a807f6/regex-2021.3.17.tar.gz\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/3e/2730d0effc282960dbff3cf91599ad0d8f3faedc8e75720fdf224b31ab24/tqdm-4.59.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from nltk) (0.14.1)\n",
      "Building wheels for collected packages: regex\n",
      "  Running setup.py bdist_wheel for regex: started\n",
      "  Running setup.py bdist_wheel for regex: finished with status 'error'\n",
      "  Complete output from command C:\\Users\\User\\anaconda3\\envs\\tensorflow-gpu\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rou9jhsm\\\\regex\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d C:\\Users\\User\\AppData\\Local\\Temp\\pip-wheel-w73y6c5j --python-tag cp35:\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.5\n",
      "  creating build\\lib.win-amd64-3.5\\regex\n",
      "  copying regex_3\\__init__.py -> build\\lib.win-amd64-3.5\\regex\n",
      "  copying regex_3\\regex.py -> build\\lib.win-amd64-3.5\\regex\n",
      "  copying regex_3\\_regex_core.py -> build\\lib.win-amd64-3.5\\regex\n",
      "  copying regex_3\\test_regex.py -> build\\lib.win-amd64-3.5\\regex\n",
      "  running build_ext\n",
      "  building 'regex._regex' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  \n",
      "  ----------------------------------------\n",
      "  Running setup.py clean for regex\n",
      "Failed to build regex\n",
      "Installing collected packages: regex, tqdm, nltk\n",
      "  Running setup.py install for regex: started\n",
      "    Running setup.py install for regex: finished with status 'error'\n",
      "    Complete output from command C:\\Users\\User\\anaconda3\\envs\\tensorflow-gpu\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rou9jhsm\\\\regex\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\User\\AppData\\Local\\Temp\\pip-record-i52chhq6\\install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.5\n",
      "    creating build\\lib.win-amd64-3.5\\regex\n",
      "    copying regex_3\\__init__.py -> build\\lib.win-amd64-3.5\\regex\n",
      "    copying regex_3\\regex.py -> build\\lib.win-amd64-3.5\\regex\n",
      "    copying regex_3\\_regex_core.py -> build\\lib.win-amd64-3.5\\regex\n",
      "    copying regex_3\\test_regex.py -> build\\lib.win-amd64-3.5\\regex\n",
      "    running build_ext\n",
      "    building 'regex._regex' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Failed building wheel for regex\n",
      "Command \"C:\\Users\\User\\anaconda3\\envs\\tensorflow-gpu\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rou9jhsm\\\\regex\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\User\\AppData\\Local\\Temp\\pip-record-i52chhq6\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-rou9jhsm\\regex\\\n",
      "You are using pip version 10.0.1, however version 20.3.4 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_2021_spring/train.csv')\n",
    "# Keeping only the neccessary columns\n",
    "df = data[['text','stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87, 4, 23, 5, 1620, 132, 146, 29, 6, 32, 2, 137, 5, 32, 355, 9, 322]\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "print(X[0])\n",
    "X = pad_sequences(X, maxlen = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice to have a diner still around food was good and comforting definitely a good spot for breakfast'\n",
      " 'tried this a while back got the fried chicken sandwich and it was meh it was pretty small and lacked the spices and flavors i was expecting in a chicken sandwich its nothing special in my opinion mary browns and kfcs chicken sandwiches are better\\r\\n\\r\\nit took super long to get 1 sandwich there was no one even in the store and it was about 7pm took a good 1520 minutes for the sandwich no combo the cashier was on her phone the whole time too not really updating me about my order'\n",
      " 'i expected more pork selections on menu food very good beer selection good pork belly app one of the best ive had schnitzel also very good will be back oddly not busy for a friday night'\n",
      " ...\n",
      " 'i first tried this place a while ago and ever since then i havent been disappointed \\r\\n\\r\\nthe place is small so its not great for big groups 6 plus just a heads up\\r\\n\\r\\nthe food there tastes like its prepped right when you order which is a big deal to me at least \\r\\n\\r\\n\\r\\n\\r\\nthey have great meal combos wrap  soup that fill you up just right  i ordered the chicken soup with the beef flank steak wrap and i have to say its probably my favourite combo there \\r\\n\\r\\nthe chicken hot broth contains a hint of spice but it balances well with the other savoury flavours the flank steak has a nice balance of freshly cut steak and sweet potatoes and the other ingredients just compliment the two main ones overall i would recommend this place to anyone who loves fusion foods its sort of a mix of westereastern from everywhere type of fusion \\r\\n\\r\\nonly downfall is space and if youre not into spicy foods your options are a little more limited that is unless you ask for certain items to be spiceless but then that defeats the purpose of the original taste'\n",
      " 'yummy yummy yummy i got the chicken fried steak huge portion i had to take half home gravy was delicious our watress was very friendly and food was delivered to our table quick we got fried macaroni  cheese as an appetizer omg was so delicious better than texas road house or bobby qs def would recommend'\n",
      " '4 stars for the beer selection 1 star for the pizza service is decent the two times i have had their pizza i was really disappointed the crust was thick and doughy and tasted like cardboard very bland toppings good thing they had some great beers to wash it down with']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 800, 128)          256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 800, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 985       \n",
      "=================================================================\n",
      "Total params: 511,785\n",
      "Trainable params: 511,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 800) (10000, 5)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['stars']).values\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('data_2021_spring/valid.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data2 = data2[['text','stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small coffee shop on the corner. Good coffee. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food was okay. Eating off styrofoam with plast...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not at all impressed with Jet...maybe its beca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We got a 14\" pepperoni pizza I'd say it feeds ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unfortunately this location has terrible custo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  Small coffee shop on the corner. Good coffee. ...      5\n",
       "1  Food was okay. Eating off styrofoam with plast...      3\n",
       "2  Not at all impressed with Jet...maybe its beca...      2\n",
       "3  We got a 14\" pepperoni pizza I'd say it feeds ...      4\n",
       "4  Unfortunately this location has terrible custo...      1"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['text'] = data2['text'].apply(lambda x: x.lower())\n",
    "data2['text'] = data2['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "    \n",
    "max_fatures = 2000\n",
    "# tokenizer.fit_on_texts(data2['text'].values)\n",
    "X_valid = tokenizer.texts_to_sequences(data2['text'].values)\n",
    "X_valid = pad_sequences(X_valid, maxlen = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(data['stars']).values\n",
    "Y_valid = pd.get_dummies(data2['stars']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  313,  136,  109],\n",
       "       [   0,    0,    0, ...,  370,  538,  160],\n",
       "       [   0,    0,    0, ...,   15,   62,    4],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  924,  104,  560],\n",
       "       [   0,    0,    0, ..., 1146, 1920, 1465],\n",
       "       [   0,    0,    0, ...,    2,   32,   29]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 800) (10000, 5)\n",
      "(2000, 800) (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train = X\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_valid.shape,Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "100/100 [==============================] - 89s 892ms/step - accuracy: 0.3734 - loss: 1.4467 - val_accuracy: 0.5085 - val_loss: 1.1816\n",
      "Epoch 2/12\n",
      "100/100 [==============================] - 90s 897ms/step - accuracy: 0.5356 - loss: 1.0872 - val_accuracy: 0.5620 - val_loss: 1.0360\n",
      "Epoch 3/12\n",
      "100/100 [==============================] - 88s 882ms/step - accuracy: 0.5913 - loss: 0.9616 - val_accuracy: 0.5650 - val_loss: 1.0459\n",
      "Epoch 4/12\n",
      "100/100 [==============================] - 89s 889ms/step - accuracy: 0.6190 - loss: 0.9087 - val_accuracy: 0.5705 - val_loss: 1.0099\n",
      "Epoch 5/12\n",
      "100/100 [==============================] - 89s 891ms/step - accuracy: 0.6303 - loss: 0.8835 - val_accuracy: 0.5645 - val_loss: 1.0503\n",
      "Epoch 6/12\n",
      "100/100 [==============================] - 90s 896ms/step - accuracy: 0.6522 - loss: 0.8360 - val_accuracy: 0.5795 - val_loss: 1.0397\n",
      "Epoch 7/12\n",
      "100/100 [==============================] - 87s 874ms/step - accuracy: 0.6688 - loss: 0.8025 - val_accuracy: 0.5735 - val_loss: 1.0518\n",
      "Epoch 8/12\n",
      "100/100 [==============================] - 90s 897ms/step - accuracy: 0.6914 - loss: 0.7515 - val_accuracy: 0.5695 - val_loss: 1.1072\n",
      "Epoch 9/12\n",
      "100/100 [==============================] - 88s 881ms/step - accuracy: 0.7037 - loss: 0.7357 - val_accuracy: 0.5615 - val_loss: 1.0825\n",
      "Epoch 10/12\n",
      "100/100 [==============================] - 88s 881ms/step - accuracy: 0.6861 - loss: 0.7780 - val_accuracy: 0.5525 - val_loss: 1.1455\n",
      "Epoch 11/12\n",
      "100/100 [==============================] - 89s 892ms/step - accuracy: 0.7219 - loss: 0.7026 - val_accuracy: 0.5660 - val_loss: 1.1150\n",
      "Epoch 12/12\n",
      " 74/100 [=====================>........] - ETA: 21s - accuracy: 0.7423 - loss: 0.6430"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "model.fit(X_train, Y_train, epochs = 12, batch_size=batch_size, verbose = 1, validation_data = (X_valid, Y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
